package pharia:skill@0.3.0-alpha.1;

world skill {
    import csi;
    export skill-handler;
}

interface skill-handler {
    /// The set of errors which may be raised by functions in this interface
    variant error {
        internal(string),
        invalid-input(string)
    }

    run: func(input: list<u8>) -> result<list<u8>, error>;
}

// A WASI interface dedicated to interacting with Large Language Models and other AI-related tasks.
interface csi {
    /// The reason the model finished generating
    enum finish-reason {
        /// The model hit a natural stopping point or a provided stop sequence
        stop,
        /// The maximum number of tokens specified in the request was reached
        length,
        /// Content was omitted due to a flag from content filters
        content-filter,
    }

    /// The result of a completion, including the text generated as well as
    /// why the model finished completing.
    record completion {
        /// The text generated by the model
        text: string,
        /// The reason the model finished generating
        finish-reason: finish-reason,
    }

    /// Completion request parameters
    record completion-params {
        /// The maximum tokens that should be inferred.
        ///
        /// Note: the backing implementation may return less tokens due to
        /// other stop reasons.
        max-tokens: option<u32>,
        /// The randomness with which the next token is selected.
        temperature: option<f64>,
        /// The number of possible next tokens the model will choose from.
        top-k: option<u32>,
        /// The probability total of next tokens the model will choose from.
        top-p: option<f64>,
        /// A list of sequences that, if encountered, the API will stop generating further tokens.
        stop: list<string>,
        /// Whether to include special tokens like `<|eot_id|>` in the completion
        special-tokens: bool
    }

    complete: func(model: string, prompt: string, params: completion-params) -> completion;

    enum role {
        user,
        assistant,
        system,
    }

    record message {
        role: role,
        content: string,
    }

    record chat-params {
        /// The maximum tokens that should be inferred.
        ///
        /// Note: the backing implementation may return less tokens due to
        /// other stop reasons.
        max-tokens: option<u32>,
        /// The randomness with which the next token is selected.
        temperature: option<f64>,
        /// The probability total of next tokens the model will choose from.
        top-p: option<f64>,
    }

    /// The result of a chat response, including the message generated as well as
    /// why the model finished completing.
    record chat-response {
        /// The message generated by the model
        message: message,
        /// The reason the model finished generating
        finish-reason: finish-reason,
    }

    chat: func(model: string, messages: list<message>, params: chat-params) -> chat-response;

    /// Chunking parameters
    record chunk-params {
        /// The name of the model the chunk is intended to be used for.
        /// This must be a known model.
        model: string,
        /// The maximum number of tokens that should be returned per chunk.
        max-tokens: u32,
    }

    chunk: func(text: string, params: chunk-params) -> list<string>;

    /// ISO 639-3
    enum language {
        /// English
        eng,
        /// German
        deu,
    }

    /// Select the detected language for the provided input based on the list of possible languages.
    /// If no language matches, None is returned.
    ///
    /// text: Text input
    /// languages: All languages that should be considered during detection.
    select-language: func(text: string, languages: list<language>) -> option<language>;

    /// Completion request parameters
    record completion-request {
        model: string,
        prompt: string,
        params: completion-params
    }

    complete-all: func(requests: list<completion-request>) -> list<completion>;

    /// Which documents you want to search in, and which type of index should be used
    record index-path {
        /// The namespace the collection belongs to
        namespace: string,
        /// The collection you want to search in
        collection: string,
        /// The search index you want to use for the collection
        index: string,
    }

    record document-path {
        namespace: string,
        collection: string,
        name: string,
    }

    record search-result {
        document-path: document-path,
        content: string,
        score: f64,
    }

    search: func(index-path: index-path, query: string, max-results: u32, min-score: option<f64>) -> list<search-result>;

    @unstable(feature=document-metadata)
    document-metadata: func(document-path: document-path) -> option<list<u8>>;
}
