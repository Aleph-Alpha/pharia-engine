package pharia:skill@0.2.1;

world skill {
    import csi;
    export skill-handler;
}

interface skill-handler {
    /// The set of errors which may be raised by functions in this interface
    variant error {
    internal(string),
    invalid-input(string)
    }

    run: func(input: list<u8>) -> result<list<u8>, error>;
}

// A WASI interface dedicated to interacting with Large Language Models and other AI-related tasks.
interface csi {
    /// The reason the model finished generating
    enum finish-reason {
    /// The model hit a natural stopping point or a provided stop sequence
    stop,
    /// The maximum number of tokens specified in the request was reached
    length,
    /// Content was omitted due to a flag from content filters
    content-filter,
    }

    /// The result of a completion, including the text generated as well as
    /// why the model finished completing.
    record completion {
    /// The text generated by the model
    text: string,
    /// The reason the model finished generating
    finish-reason: finish-reason,
    }

    /// Completion request parameters
    record completion-params {
    /// The maximum tokens that should be inferred.
    ///
    /// Note: the backing implementation may return less tokens due to
    /// other stop reasons.
    max-tokens: option<u32>,
    /// The randomness with which the next token is selected.
    temperature: option<float64>,
    /// The number of possible next tokens the model will choose from.
    top-k: option<u32>,
    /// The probability total of next tokens the model will choose from.
    top-p: option<float64>,
    /// A list of sequences that, if encountered, the API will stop generating further tokens.
    stop: list<string>,
    }

    complete: func(model: string, prompt: string, params: completion-params) -> completion;

    /// Chunking parameters
    record chunk-params {
    /// The name of the model the chunk is intended to be used for.
    /// This must be a known model.
    model: string,
    /// The maximum number of tokens that should be returned per chunk.
    max-tokens: u32,
    }

    chunk: func(text: string, params: chunk-params) -> list<string>;
}
